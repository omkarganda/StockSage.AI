# StockStage.AI â”€ Project Structure

Below is a recommended, productionâ€‘ready layout for the **StockStage.AI** repository.  It separates concerns clearlyâ€”data, features, models, evaluation, and deploymentâ€”making collaboration, testing, and CI/CD straightforward.

```text
StockStage.AI/
â”œâ”€â”€ data/                       # Local data storage (gitâ€‘ignored)
â”‚   â”œâ”€â”€ raw/                    # Unmodified downloads from APIs
â”‚   â”œâ”€â”€ processed/              # Cleaned & featureâ€‘rich datasets
â”‚   â””â”€â”€ external/               # Any 3rdâ€‘party data snapshots / benchmarks
â”‚
â”œâ”€â”€ notebooks/                  # Exploratory analysis & prototyping
â”‚   â”œâ”€â”€ 01_exploration.ipynb
â”‚   â””â”€â”€ 02_modeling.ipynb
â”‚
â”œâ”€â”€ src/                        # Core Python package (pipâ€‘installable)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Global paths, API keys (reads .env)
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                   # Data ingestion & alignment
â”‚   â”‚   â”œâ”€â”€ download_market.py          # yfinance wrappers
â”‚   â”‚   â”œâ”€â”€ download_economic.py        # FRED / other macro APIs
â”‚   â”‚   â”œâ”€â”€ download_sentiment.py       # FinBERT-based sentiment data collection
â”‚   â”‚   â””â”€â”€ merge.py                    # Combine & timeâ€‘sync datasets
â”‚   â”‚
â”‚   â”œâ”€â”€ features/               # Feature engineering & sentiments
â”‚   â”‚   â”œâ”€â”€ indicators.py               # TA indicators, moving avgs, RSI â€¦
â”‚   â”‚   â””â”€â”€ sentiment.py                # FinBERT model inference + LangChain helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Forecasting & generative models
â”‚   â”‚   â”œâ”€â”€ neuralforecast_model.py     # NEW: Replace prophet_model.py  
â”‚   â”‚   â”œâ”€â”€ sktime_model.py            # NEW: Replace darts_model.py
â”‚   â”‚   â”œâ”€â”€ lightning_model.py         # Keep existing
â”‚   â”‚   â””â”€â”€ openai_scenario.py         # Keep existing
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/             # Backtesting & metrics
â”‚   â”‚   â”œâ”€â”€ backtester.py               # Walkâ€‘forward & crossâ€‘val engine
â”‚   â”‚   â””â”€â”€ metrics.py                  # MAPE, RMSE, Sharpeâ€‘ratio, drawdowns
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/          # Plotting utilities (Plotly)
â”‚   â”‚   â””â”€â”€ plots.py
â”‚   â”‚
â”‚   â””â”€â”€ app/                    # Production interface
â”‚       â”œâ”€â”€ dashboard.py                # Streamlit/Dash interactive UI
â”‚       â””â”€â”€ api.py                     # FastAPI endpoints for predictions
â”‚
â”œâ”€â”€ scripts/                    # CLI entryâ€‘points for automation
â”‚   â”œâ”€â”€ train.py                # Orchestrates full training pipeline
â”‚   â”œâ”€â”€ evaluate.py             # Generates backtesting reports
â”‚   â””â”€â”€ run_dashboard.sh        # Convenience launcher for the web app
â”‚
â”œâ”€â”€ tests/                      # PyTest suites (unit + integration)
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ config/                     # YAML/JSON configs (hyperâ€‘params, logging)
â”‚   â”œâ”€â”€ model_params.yaml         # Keep existing
â”‚   â”œâ”€â”€ logging.yaml              # Keep existing  
â”‚   â””â”€â”€ experiment_config.yaml    # NEW: W&B experiment configuration
â”‚
â”œâ”€â”€ .env.template               # API keys & secrets (copy to .env)
â”œâ”€â”€ requirements.txt              # Add: neuralforecast, sktime, finbert, polars, wandb
â”œâ”€â”€ README.md                   # Project overview & quickâ€‘start
â””â”€â”€ LICENSE
```

---

## File & Directory Descriptions

| Path              | Purpose                                                                                                            |
| ----------------- | ------------------------------------------------------------------------------------------------------------------ |
| **data/**         | Keeps the dataset hierarchy tidy. *Never commit raw data*â€”add `data/` to `.gitignore`.                             |
| **notebooks/**    | Jupyter/Colab notebooks for initial EDA, quick experiments, and presentations.                                     |
| **src/**          | Installable Python package (`pip install -e .`). All production code lives here, logically split into subâ€‘modules. |
| **scripts/**      | Oneâ€‘shot or scheduled commandâ€‘line utilitiesâ€”ideal for cron/Airflow jobs.                                          |
| **tests/**        | Ensures every critical function is unitâ€‘ or integrationâ€‘tested before deployment.                                  |
| **app/**          | Realâ€‘time serving layer: interactive dashboard and REST endpoints.                                                 |
| **config/**       | Central location for hyperâ€‘parameters, experiment tracking settings, and logging formats.                          |
| **.env.template** | Shows expected environment variables without exposing secretsâ€”copy/rename to `.env`.                               |

---

## Getting Started (README snippet)

```bash
# clone repo & install
$ git clone https://github.com/omkarganda/StockStage.AI.git && cd StockStage.AI
$ python -m venv .venv && source .venv/bin/activate
$ pip install -r requirements.txt

# download default datasets & preprocess
$ python scripts/train.py --stage fetch

# full training run (incl. backtesting)
$ python scripts/train.py --stage full

# launch dashboard
$ ./scripts/run_dashboard.sh
```

Feel free to adapt naming conventions, add Docker, CI workflows, or Terraform for cloud infra as the project matures.

## **1. First, create the `.env.template` file:**

You'll need to manually create this file in your root directory:

```bash
# .env.template

# StockStage.AI Environment Variables Template
# Copy this file to .env and fill in your actual API keys

# =============================================================================
# ESSENTIAL API KEYS (Required for core functionality)
# =============================================================================

# Economic Data - Federal Reserve Economic Data (FREE)
# Get your key at: https://fred.stlouisfed.org/docs/api/
FRED_API_KEY=your_fred_api_key_here

# News Sentiment Data - NewsAPI (FREE tier: 500 requests/day)
# Get your key at: https://newsapi.org/
NEWS_API_KEY=your_news_api_key_here

# OpenAI API for GPT-powered insights and explainability
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# OPTIONAL API KEYS (For enhanced functionality)
# =============================================================================

# Alternative Market Data - Alpha Vantage (FREE tier available)
# Get your key at: https://www.alphavantage.co/support/#api-key
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key_here

# Financial News - Finnhub (FREE tier available)  
# Get your key at: https://finnhub.io/register
FINNHUB_API_KEY=your_finnhub_key_here

# Weights & Biases for experiment tracking (FREE account available)
# Get your key at: https://wandb.ai/authorize
WANDB_API_KEY=your_wandb_api_key_here

# Hugging Face API for advanced NLP models (FREE tier available)
# Get your key at: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_key_here

# Environment settings
ENVIRONMENT=development
DEBUG=true
```

## **2. Now, create the exploration notebook:**

Create `notebooks/01_exploration.ipynb` with this content:

```python
<code_block_to_apply_changes_from>
```

## **ðŸŽ¯ Steps to Test:**

1. **Create the files manually:**
   - Copy the `.env.template` content to a new file called `.env.template`
   - Copy the notebook content to `notebooks/01_exploration.ipynb`

2. **Get your API keys:**
   - **FRED**: https://fred.stlouisfed.org/docs/api/ (FREE)
   - **NewsAPI**: https://newsapi.org/ (FREE tier: 500 requests/day)
   - **OpenAI**: https://platform.openai.com/api-keys (Paid, but cheap for testing)

3. **Copy .env.template to .env and add your keys:**
   ```bash
   cp .env.template .env
   # Edit .env with your actual API keys
   ```

4. **Install additional packages:**
   ```bash
   pip install newsapi-python python-dotenv
   ```

5. **Run the notebook:**
   ```bash
   jupyter notebook notebooks/01_exploration.ipynb
   ```

This notebook will test all your data sources and show you exactly what's working and what needs API keys! ðŸš€

